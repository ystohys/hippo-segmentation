{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612651a3-6fec-473c-a906-38c4e2ec9af7",
   "metadata": {},
   "source": [
    "## Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f9f2a-cf42-4ded-80ef-344080f0784b",
   "metadata": {},
   "source": [
    "Before beginning the preprocessing steps below, please ensure that all of the MRI data are stored in a directory (for e.g. \"./mri_data/\"). Please make sure that each subject (e.g. 002_S_0295) has his/her scans stored under a folder with his/her subject ID as the folder name. Please also note that any files belonging to subjects with unusual anatomy or with a different scanning orientation **must be removed**. You may remove these files before or after you complete all the preprocessing steps, since the preprocessing occurs on a per-image basis and will not affect the other images. However, they **must be removed** before you extract the region of interest.\n",
    "\n",
    "The subject IDs of these subjects that are to be removed are as stated in this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed25d8-6d1a-4e8e-b9f5-571eba4a5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "to_remove = ['023_S_0604', '130_S_4730', '023_S_0331', '130_S_0956',\n",
    "             '013_S_1186', '067_S_1185', '006_S_4449', '019_S_4252', \n",
    "             '013_S_4731', '098_S_0172', '023_S_1289', '020_S_1288',\n",
    "             '023_S_0061', '012_S_1321', '002_S_1261', '002_S_1070', \n",
    "             '002_S_1280', '002_S_1155', '023_S_1247', '002_S_0954']\n",
    "\n",
    "subj_data_path = 'znorm_stripped_imgs'  # Key in the folder name here to remove all these files\n",
    "for subj in os.listdir(subj_data_path):\n",
    "    if subj in to_remove:\n",
    "        shutil.rmtree(os.path.join(subj_data_path, subj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28703198-35d5-40aa-a496-812fb8b761ef",
   "metadata": {},
   "source": [
    "The NIFTI file that contains the raw scan of the entire brain should be labelled {subject_id}\\_raw.nii, the NIFTI files that contains the segmentation masks of the left and right hippocampus should be labelled ADNI\\_{subject_id}\\_L.nii and ADNI\\_{subject_id}\\_R.nii respectively.\n",
    "\n",
    "    > mri_data\n",
    "        >> unprocessed_data\n",
    "            >>> 002_S_0295\n",
    "                >>>> 002_S_0295_raw.nii\n",
    "                >>>> ADNI_002_S_0295_L.nii\n",
    "                >>>> ADNI_002_S_0295_R.nii\n",
    "            >>> 002_S_0059\n",
    "                >>>> ...\n",
    "\n",
    "To start, we perform the following steps (in this exact ordering):\n",
    "\n",
    "1. Bias Field Correction using N4 Bias Field Correction\n",
    "2. Brain extraction (skullstripping) using ROBEX\n",
    "3. Intensity normalization using WhiteStripe normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac69a3-e9a1-4c47-9a22-de774b0788e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.preprocessing import *\n",
    "\n",
    "path_to_data = 'mri_data/unprocessed_data'  # Change this according to your path\n",
    "\n",
    "#n4bfc(path_to_data)\n",
    "#brain_extraction(path_to_data)\n",
    "#ws_intensity_norm(path_to_data)\n",
    "#fcm_gm_intensity_norm(path_to_data)\n",
    "zs_intensity_norm(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5688f3e-7a08-4919-b8cb-0a1389c1353d",
   "metadata": {},
   "source": [
    "After the above steps have been completed, the processed brain images should be in a newly created folder called 'mri_data/wsnorm_stripped_imgs'. We will then port over the hippocampus segmentation masks from the old folder using the port_over_masks function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc759c-ef88-485d-8d27-599e39ba05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.preprocessing import port_over_masks\n",
    "port_over_masks(\n",
    "    'unprocessed_data', # old folder\n",
    "    'znorm_stripped_imgs' # new folder\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc923d-eb9b-4c7f-afff-ec9688db27ca",
   "metadata": {},
   "source": [
    "Each subject's folder should contain the preprocessed brain MRI and the two hippocampus segmentation masks. I strongly recommend you to pull all the folders under 'mri_data/wsnorm_stripped_imgs' into a new folder called 'precrop_final_data1' that is on the same 'level' as the mri_data folder. This will reduce the chances of pathing errors. If done correctly, your current working directory should look something like this:\n",
    "\n",
    "    > mri_data\n",
    "        >> ...\n",
    "    > precrop_final_data1\n",
    "        >> 002_S_0295\n",
    "            >>> ADNI_002_S_0295_L.nii\n",
    "            >>> ADNI_002_S_0295_R.nii\n",
    "            >>> 002_S_0295_wsnormed.nii\n",
    "        >> 002_S_0059\n",
    "            >>> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a8ed0-5e0d-4515-a3ce-fdf9d1af8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizing the intensity distribution\n",
    "\n",
    "from data_utils.preprocessing import plot_intensity_dist\n",
    "\n",
    "# plot_intensity_dist(imgs_path='unnorm_stripped_imgs', \n",
    "#                     img_suffix='stripped.nii', \n",
    "#                     mask_suffix='masked.nii', \n",
    "#                     cropped=False,\n",
    "#                     title='Unnormalized intensities')\n",
    "\n",
    "# plot_intensity_dist(imgs_path='znorm_stripped_imgs', \n",
    "#                     img_suffix='znorm.nii', \n",
    "#                     mask_suffix='masked.nii', \n",
    "#                     cropped=False,\n",
    "#                     title='Z-score normalized intensities')\n",
    "\n",
    "# plot_intensity_dist(imgs_path='wsnorm_stripped_imgs', \n",
    "#                     img_suffix='wsnorm.nii', \n",
    "#                     mask_suffix='masked.nii', \n",
    "#                     cropped=False,\n",
    "#                     title='WS Norm intensities')\n",
    "\n",
    "# plot_intensity_dist(imgs_path='ws_mm_stripped_imgs', \n",
    "#                     img_suffix='wsnorm.nii', \n",
    "#                     mask_suffix='masked.nii', \n",
    "#                     cropped=False,\n",
    "#                     title='WS Norm + MinMax-ed intensities')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14267ce-bbf0-48e5-8b3f-76f59dafd27a",
   "metadata": {},
   "source": [
    "## Extracting region of interest around the hippocampus\n",
    "\n",
    "**Please make sure you have removed the 20 subjects that have incorrect orientation or unusual anatomy and corrected the mislabelled left and right hippocampus for the other 4 subjects stated below, before you proceed to the next steps\\!** \n",
    "\n",
    "Next we crop the images to obtain the region surrounding the hippocampus. This is obtained by going over every image and detecting the maximal 'boundaries' of the hippocampus along the axial, sagittal and coronal views.\n",
    "\n",
    "While examining the images, I realised that the hippocampus masks files were incorrectly labelled (L should be R, R should be L) for the following four subjects:\n",
    "\n",
    "* 007_S_1304\n",
    "* 016_S_4121\n",
    "* 029_S_4279\n",
    "* 136_S_0429\n",
    "\n",
    "Please **ensure that they are corrected by renaming these files**. For example, 'ADNI_007_S_1304_L.nii' should be renamed to 'ADNI_007_S_1304_R.nii' and 'ADNI_007_S_1304_R.nii' should be renamed to 'ADNI_007_S_1304_L.nii'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e42fb-8ed8-4610-9a70-e92f063bb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.preprocessing import find_max_boundary, get_bounding_boxes\n",
    "\n",
    "left, right = find_max_boundary('ws_mm_stripped_imgs')\n",
    "print(left)\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133a1d8-e009-4eb3-9e63-a258de9b7279",
   "metadata": {},
   "source": [
    "We then further expand the boundaries to obtain bounding boxes with dimensions that are evenly numbered, so as to avoid dimension shape incompatibility, since our U-Net based models performs downsampling followed by upsampling. Our region of interest is a bounding box/cuboid with dimensions of $40 \\times 56 \\times 72$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73d296-7716-4005-98f7-08f8c5cc8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each input has dimensions 40x56x72\n",
    "left = [[57, 96+1], [77, 132+1], [37, 108+1]]\n",
    "right = [[100, 139+1], [81, 136+1], [38, 109+1]]\n",
    "#get_bounding_boxes(left, right, 'fcmnorm_gm_stripped_imgs', 'fcmnorm.nii', 'fcm_gm_cropped_imgs')\n",
    "#get_bounding_boxes(left, right, 'wsnorm_stripped_imgs', 'wsnorm.nii', 'ws_cropped_imgs')\n",
    "#get_bounding_boxes(left, right, 'unnorm_stripped_imgs', 'stripped.nii', 'unnorm_cropped_imgs')\n",
    "#get_bounding_boxes(left, right, 'znorm_stripped_imgs', 'znorm.nii', 'znorm_cropped_imgs')\n",
    "get_bounding_boxes(left, right, 'ws_mm_stripped_imgs', 'wsnorm.nii', 'ws_mm_cropped_imgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c8f6a-dc16-4cf5-b37b-8cd58a6fc8e2",
   "metadata": {},
   "source": [
    "All the cropped and intensity normalized images are in your new folder(s) as specified in the `get_bounding_boxes` function.\n",
    "\n",
    "We use `plot_intensity_dist` function to visualise the distribution of the intensities for the regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bda211-9fce-4adc-92df-21d13e430bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.preprocessing import minmax_scale\n",
    "\n",
    "minmax_scale('wsnorm_stripped_imgs', 'ws_mm1_stripped_imgs', 'wsnorm.nii', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c2b54-90f0-4530-a8fe-dd393e76c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.preprocessing import plot_intensity_dist\n",
    "# plot_intensity_dist(imgs_path='unnorm_cropped_imgs', \n",
    "#                     img_suffix='LB.nii',\n",
    "#                     title='Unnormalized intensities for left brain ROI',\n",
    "#                     cropped=True)\n",
    "plot_intensity_dist(imgs_path='znorm_cropped_imgs',\n",
    "                    img_suffix='LB.nii',\n",
    "                    title='Z-normalized intensities for left brain ROI',\n",
    "                    cropped=True)\n",
    "plot_intensity_dist(imgs_path='ws_cropped_imgs', \n",
    "                    img_suffix='LB.nii',\n",
    "                    title='WS Norm-ed intensities for left brain ROI',\n",
    "                    cropped=True)\n",
    "plot_intensity_dist(imgs_path='ws_mm_cropped_imgs', \n",
    "                    img_suffix='LB.nii',\n",
    "                    title='WS + MinMax-ed intensities for left brain ROI',\n",
    "                    cropped=True)\n",
    "\n",
    "# plot_intensity_dist(imgs_path='fcm_cropped_imgs', \n",
    "#                     img_suffix='RB.nii',\n",
    "#                     title='FCM Norm-ed intensities for right brain ROI',\n",
    "#                     cropped=True)\n",
    "# plot_intensity_dist(imgs_path='ws_cropped_imgs', \n",
    "#                     img_suffix='RB.nii',\n",
    "#                     title='WS Norm-ed intensities for right brain ROI',\n",
    "#                     cropped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061de84-dd43-4947-aaad-5fb0f22056b8",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training, validation and test sets\n",
    "\n",
    "Our full dataset consists of 115 subjects, each with two regions of the brain (left and right) to perform hippocampus segmentation on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31b678-e8d5-42bb-8af7-05cf364eb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "valid_subjects = os.listdir('znorm_cropped_imgs')\n",
    "harp_meta = pd.read_csv('harp_metadata.csv')\n",
    "harp_meta = harp_meta.loc[harp_meta['Subject'].isin(valid_subjects), \n",
    "                          ['Subject', 'Group', 'Age', 'Sex']]\n",
    "\n",
    "\n",
    "train_meta, test_meta = train_test_split(harp_meta, \n",
    "                                         test_size=25, \n",
    "                                         random_state=42,\n",
    "                                         shuffle=True,\n",
    "                                         stratify=harp_meta['Group'])\n",
    "\n",
    "train_ids = list(train_meta['Subject'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff866154-0b7a-470b-9720-12c9f0f5f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "def deco(func):\n",
    "    @functools.wraps(func)\n",
    "    def inner(*args, **kwargs):\n",
    "        start = datetime.datetime.now()\n",
    "        func(*args, **kwargs)\n",
    "        finish = datetime.datetime.now()\n",
    "        print(\"Total time taken: {0:.5f} seconds\".format((finish-start).total_seconds()))\n",
    "    \n",
    "    return inner\n",
    "\n",
    "@deco\n",
    "def train_model():\n",
    "    print(\"MODEL TRAINING NOW\")\n",
    "    \n",
    "    \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2200eaa-da43-45fe-b2fc-05de614d3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "str.upper(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad52fea-bb8d-4517-8298-ddb85d1e302b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
